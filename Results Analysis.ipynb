{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from copyreg import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.lines import lineStyles\n",
    "from networkx.algorithms.bipartite.basic import color\n",
    "\n",
    "from model import model\n",
    "from DataExtraction import utils\n",
    "import os\n",
    "import ujson"
   ],
   "id": "2ce95703e3702366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load, from each model, the results, the model configuration and the evaluation metrics\n",
    "os.chdir(utils.get_root_dir() + '/model/final_models')\n",
    "n_models = len([name for name in os.listdir('.') if 'model_' in name])\n",
    "training_stats, testing_stats, model_results, model_info = {}, {}, {}, {}\n",
    "for i in range(1, n_models + 1):\n",
    "    m = model.load_model(f'model_{i}')\n",
    "    model_info[m.model_config.model_name] = m.model_config.__dict__\n",
    "    # Print name and num of parameters for each model\n",
    "    print(m.model_config.model_name, sum(p.numel() for p in m.parameters()))\n",
    "    with open(m.model_config.model_src + '/train/training_stats.json', 'r') as f:\n",
    "        training_stats[m.model_config.model_name] = ujson.load(f)\n",
    "    with open(m.model_config.model_src + '/test/losses.json', 'r') as f:\n",
    "        testing_stats[m.model_config.model_name] = ujson.load(f)\n",
    "    model_results[m.model_config.model_name] = np.load(m.model_config.model_src + '/test/y_pred.npy'), np.load(m.model_config.model_src + '/test/y_test.npy')\n",
    "    del m"
   ],
   "id": "ab77357818ec7357"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_model_information(model_name, training_stats, testing_stats, model_results, model_info, results_df):\n",
    "    model_type = model_info['model_type']\n",
    "    temporal_window = model_info['window_size'] if model_type == 'LSTM' else str(model_info['window_size']) + '/' + str(model_info['subwindow_size'])\n",
    "    training_time = sum(training_stats['epoch_times'])\n",
    "    # num_params = sum(model_info['num_parameters'])\n",
    "    epoch_num = max(training_stats['epoch_num'])\n",
    "    layers_blocks = model_info['num_layers'] if model_type == 'LSTM' else model_info['xLSTM_config'].num_blocks\n",
    "    batch_size = model_info['batch_size']\n",
    "    dropout = model_info['dropout']\n",
    "    learning_rate = model_info['lr']\n",
    "    mse = testing_stats['total']['mse']\n",
    "    mae = testing_stats['total']['mae']\n",
    "    rmse = testing_stats['total']['rmse']\n",
    "    r2 = testing_stats['total']['r2']\n",
    "    results_df[model_name] = {\n",
    "        'Type': model_type,\n",
    "        'Temporal Window': temporal_window,\n",
    "        'Training Time': training_time,\n",
    "        # 'Number of Parameters': num_params,\n",
    "        'Number of Epochs': epoch_num,\n",
    "        'Layers/Blocks': layers_blocks,\n",
    "        'Batch Size': batch_size,\n",
    "        'Dropout': dropout,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    }"
   ],
   "id": "86be552fab9a4930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "final_df = pd.DataFrame(index=['Type', 'Temporal Window', 'Training Time', 'Number of Epochs', 'Layers/Blocks', 'Batch Size', 'Dropout', 'Learning Rate', 'MSE', 'MAE', 'RMSE', 'R2'])",
   "id": "9f36e33473db06b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for model_name in model_info.keys():\n",
    "    get_model_information(model_name, training_stats[model_name], testing_stats[model_name], model_results[model_name], model_info[model_name], final_df)"
   ],
   "id": "df7841831789de7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "final_df.iloc[:,24:]",
   "id": "e3f62633bad063d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# MODEL CLASSIFICATION\n",
    "# By Model Number\n",
    "m1 = {'model_1': 30, 'model_2': 90, 'model_3': 180, 'model_4': 365}\n",
    "m2 = {'model_5': 30, 'model_6': 90, 'model_7': 180, 'model_8': 365}\n",
    "m3 = {'model_9': 30, 'model_10': 90, 'model_11': 180, 'model_12': 365}\n",
    "m4 = {'model_13': 30, 'model_14': 90, 'model_15': 180, 'model_16': 365}\n",
    "m5 = {'model_29': 30, 'model_30': 90, 'model_31': 180, 'model_32': 365}\n",
    "m6 = {'model_21': 30, 'model_22': 90, 'model_23': 180, 'model_24': 365}\n",
    "m7 = {'model_25': 30, 'model_26': 90, 'model_27': 180, 'model_28': 365}\n",
    "all_models_by_number = {f'Model {[m1, m2, m3, m4, m5, m6, m7].index(m)+1}': m for m in [m1, m2, m3, m4, m5, m6, m7]}\n",
    "# By Steps Forward\n",
    "sfw_30 = ['model_1', 'model_5', 'model_9', 'model_13', 'model_29', 'model_21', 'model_25']\n",
    "sfw_90 = ['model_2', 'model_6', 'model_10', 'model_14', 'model_30', 'model_22', 'model_26']\n",
    "sfw_180 = ['model_3', 'model_7', 'model_11', 'model_15', 'model_31', 'model_23', 'model_27']\n",
    "sfw_365 = ['model_4', 'model_8', 'model_12', 'model_16', 'model_32', 'model_24', 'model_28']\n",
    "all_models_by_sfw = [sfw_30, sfw_90, sfw_180, sfw_365]\n",
    "possible_models = [f'Model {i}' for i in range(1, 8)]\n",
    "\n",
    "best_models_30 = [sfw_30[1], sfw_30[-1]]\n",
    "best_models_90 = [sfw_90[1], sfw_90[-1]]\n",
    "best_models_180 = [sfw_180[1], sfw_180[-1]]\n",
    "best_models_365 = [sfw_365[1], sfw_365[-1]]"
   ],
   "id": "cfc0f8d28b5817de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_pred(model_name, model_results, sensor):\n",
    "    return model_results[model_name][0].T[sensor]\n",
    "def get_test(model_results, sensor):\n",
    "    return model_results['model_1'][1].T[sensor]"
   ],
   "id": "78be0512dce6cb91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_same_sfw_predictions(sensors, model_results, models, days):\n",
    "    fix, ax = plt.subplots(3, 3, figsize=(20, 20))\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    plt.title(f'Prediction within {days} days')\n",
    "    for s in range(len(sensors)):\n",
    "        sensor = sensors[s]\n",
    "        # Get predictions and test data\n",
    "        y_pred = [get_pred(model, model_results, sensor) for model in models]\n",
    "        y_test = get_test(model_results, sensor)\n",
    "        # Min prediction length\n",
    "        min_len = min(len(y) for y in y_pred)\n",
    "        y_pred = [y[-min_len:] for y in y_pred]\n",
    "        y_test = y_test[-min_len:]\n",
    "        # Get numbers to match result table\n",
    "        model_corrected_number = [i for model in models for i in possible_models if model in all_models_by_number[i]]\n",
    "        # Plot results for each sensor\n",
    "        ax.flat[s].plot(y_test, label='True', color='black', linestyle='dashed')\n",
    "        for model_num, y in zip(model_corrected_number, y_pred):\n",
    "            ax.flat[s].plot(y, label=model_num, color=cmap(model_corrected_number.index(model_num)))\n",
    "            ax.flat[s].set_title(f'Sensor {s + 1}')\n",
    "            ax.flat[s].legend()\n",
    "    plt.show()"
   ],
   "id": "1f8a66c8bb3d24ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 30 days ahead prediction\n",
    "plot_same_sfw_predictions([s for s in range(0, 9)], model_results, best_models_30,  days=30)"
   ],
   "id": "c91628eb589e464d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 90 days ahead prediction\n",
    "plot_same_sfw_predictions([s for s in range(0, 9)], model_results, best_models_90,  days=90)"
   ],
   "id": "69021eeb2b313b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 180 days ahead prediction\n",
    "plot_same_sfw_predictions([s for s in range(0, 9)], model_results, best_models_180,  days=180)"
   ],
   "id": "80beeb8a85ea0509"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 365 days ahead prediction\n",
    "plot_same_sfw_predictions([s for s in range(0, 9)], model_results, best_models_365,  days=365)"
   ],
   "id": "a40c02aecc104eae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get errors for best models 30 days ahead for all sensors\n",
    "def get_errors(testing_stats, models):\n",
    "    errors = {}\n",
    "    for model in models:\n",
    "        errors[model] = testing_stats[model]\n",
    "    return errors\n",
    "\n",
    "errors_30 = get_errors(testing_stats, best_models_30)"
   ],
   "id": "fcc42f200777e917"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "errors_m2 = pd.DataFrame(errors_30['model_5'],)\n",
    "errors_m2['Model'] = 'Model 2'\n",
    "errors_m2.reset_index(inplace=True)\n",
    "errors_m2.set_index(['Model', 'index'], inplace=True)\n",
    "errors_m2.index.names = ['Model', 'Metric']"
   ],
   "id": "6c04a01fb3dd61ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "errors_m2",
   "id": "adca4864964a7c3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "errors_m7 = pd.DataFrame(errors_30['model_25'])\n",
    "errors_m7['Model'] = 'Model 7'\n",
    "errors_m7.reset_index(inplace=True)\n",
    "errors_m7.set_index(['Model', 'index'], inplace=True)\n",
    "errors_m7.index.names = ['Model', 'Metric']"
   ],
   "id": "97b7fdadfd79988f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "errors_m7",
   "id": "299d59455e5a77af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results_30_per_sensor = pd.concat([errors_m2, errors_m7]).T\n",
    "results_30_per_sensor[['Model 7']]"
   ],
   "id": "5c976f2bc58e5246"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "# Get scalers from Model 2 and Model 7\n",
    "def get_scaler(model_name):\n",
    "    with open(utils.get_root_dir()+f'/model/final_models/{model_name}/scalers.pkl', 'rb') as f:\n",
    "        x_scaler, y_scaler = pickle.load(f)\n",
    "    return x_scaler, y_scaler\n",
    "scalers_m2 = [get_scaler(m) for m in m2.keys()]\n",
    "scalers_m7 = [get_scaler(m) for m in m7.keys()]"
   ],
   "id": "b9c0fa2320356e75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert y_pred for each model to the real scale (Model 2)\n",
    "y_pred_m2 = []\n",
    "for m in range(0, 4):\n",
    "    y_pred = []\n",
    "    for s in range(0, 9):\n",
    "        y_pred.append(get_pred(list(m2.keys())[m], model_results, s))\n",
    "    y_pred_m2.append(y_pred)\n",
    "y_pred_m2 = [scalers_m2[i][1].inverse_transform(np.array(y_pred_m2[i]).T) for i in range(0, 4)]"
   ],
   "id": "57f37fc27b1bd585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert y_pred for each model to the real scale (Model 7)\n",
    "y_pred_m7 = []\n",
    "for m in range(0, 4):\n",
    "    y_pred = []\n",
    "    for s in range(0, 9):\n",
    "        y_pred.append(get_pred(list(m7.keys())[m], model_results, s))\n",
    "    y_pred_m7.append(y_pred)\n",
    "y_pred_m7 = [scalers_m7[i][1].inverse_transform(np.array(y_pred_m7[i]).T) for i in range(0, 4)]"
   ],
   "id": "56988babe3a52b06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert y_test for each model to the real scale\n",
    "y_test = []\n",
    "for m in range(0, 4):\n",
    "    y_test_ = []\n",
    "    for s in range(0, 9):\n",
    "        y_test_.append(get_test(model_results, s))\n",
    "    y_test.append(y_test_)\n",
    "y_test = [scalers_m7[i][1].inverse_transform(np.array(y_test[i]).T) for i in range(0, 4)]"
   ],
   "id": "f56477abe0039ee2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot 30 days predictions for sensor 2 and sensor 9\n",
    "cmap = plt.get_cmap('Paired')\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax[0].plot(y_test[0][:, 1], label='Real', linestyle='--', color='black',)\n",
    "ax[0].plot(y_pred_m2[0][:, 1], label=f'Model 2', color=cmap(0))\n",
    "ax[0].plot(y_pred_m7[0][:, 1], label=f'Model 7', color = cmap(1))\n",
    "ax[0].set_title('Sensor 1 - 30 days ahead (real scale)')\n",
    "ax[0].legend()\n",
    "ax[1].plot(y_test[0][:, 8], label='Real', linestyle='--', color='black',)\n",
    "ax[1].plot(y_pred_m2[0][:, 8], label=f'Model 2', color=cmap(0))\n",
    "ax[1].plot(y_pred_m7[0][:, 8], label=f'Model 7', color = cmap(1))\n",
    "ax[1].set_title('Sensor 9 - 30 days ahead (real scale)')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ],
   "id": "c4f14d8042cf21b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_test[0]",
   "id": "c1ffef01c4faf69e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:36:17.308571Z",
     "start_time": "2024-12-10T23:36:17.307389Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4565fd15a1e626d5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
